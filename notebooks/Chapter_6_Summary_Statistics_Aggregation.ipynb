{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "521cc048",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.25\"> \n",
    "\n",
    "![Analysis Function and DSC Logo](../images/AF_DSC_banner.png)\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.25\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d259eb",
   "metadata": {},
   "source": [
    "# Introduction to Python\n",
    "\n",
    "## Chapter 6 - Summary Statistics & Aggregation\n",
    "\n",
    "\n",
    "*Chapter Overview and Learning Objectives*:\n",
    "\n",
    "* [Packages and Data](#packages)\n",
    " - Packages\n",
    " - Data\n",
    " \n",
    "* [Overall Descriptive Statistics](#describe)\n",
    "\n",
    "* [Range](#range)\n",
    " - min\n",
    " - max\n",
    " - quantiles\n",
    " \n",
    "* [Averages](#averages)\n",
    " - Mean\n",
    " - Median\n",
    " - Mode\n",
    " \n",
    "* [Spread](#spread)\n",
    " - Standard Deviation\n",
    " - Variance\n",
    "\n",
    "* [Counting Values](#count)\n",
    " - Counts\n",
    " - Null Value counts\n",
    " - Value Counts\n",
    "\n",
    "* [Other Summary Statistics](#other)\n",
    "\n",
    "* [Creating Size Bands](#cut)\n",
    "\n",
    "* [Aggregation](#agg)\n",
    " - Single Aggregation\n",
    " - Multiple Aggregation\n",
    "\n",
    "<a id='packages'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52862ce3",
   "metadata": {},
   "source": [
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc761c",
   "metadata": {},
   "source": [
    "# Packages and Datasets\n",
    "\n",
    "## Packages\n",
    "As a reminder, we should always import our packages at the top of our script. In this session we will use the following:\n",
    "\n",
    "* `pandas`, and give it the nickname `pd`\n",
    "* `numpy` and give it the nickname `np`\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Import Pandas and give it the nickname pd\n",
    "Import Numpy and give it the nickname np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a23e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca75315",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Good practice also dictates that we read in our datasets at the top of our script too.\n",
    "\n",
    "In this session we’ll be using:\n",
    "\n",
    "* animals - animals.csv \n",
    "* titanic - titanic.xlsx \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Load in these datasets listed above\n",
    "\n",
    "You can check your variables are loaded by using `%whos` in Jupyter. In Spyder or other IDE's they should appear in your variable explorer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9bd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9100e73",
   "metadata": {},
   "source": [
    "If you struggle with this section, feel free to review the content of Chapter 3 that covered this in depth. Practicing these commands that we repeat over and over is a great way to retain the good practice guidelines. \n",
    "\n",
    "[return to menu](#menu)\n",
    "\n",
    "<a id='describe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc365993",
   "metadata": {},
   "source": [
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae45bb",
   "metadata": {},
   "source": [
    "# Overall Descriptive Statistics\n",
    "\n",
    "Pandas has an inbuilt method to get basic descriptive statistics across our dataset, this is the `.describe()` method.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0639af",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c920b5c",
   "metadata": {},
   "source": [
    "We can also get summary statistics on a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa413977",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e0286",
   "metadata": {},
   "source": [
    "These statistics are explained in more detail below:\n",
    " \n",
    " | Summary Statistic | Description|\n",
    " |--------------------------|-----------------|\n",
    "| count | the number (count) of non missing entries in the given column.\n",
    "| mean | the average (arithmetic mean) data value in the given column.\n",
    "| std | the standard deviation (spread) of values in the given column.\n",
    "| min |  the smallest value in the given column.\n",
    "| 25% | the value of the data at the lower quartile <br> (i.e. after the first 25% of data, ordered from smallest to largest).\n",
    "| 50% | the middle value of the data (aka the median). <br> half the values are larger than this value, and half smaller.\n",
    "| 75% | the value of the data at the upper quartile <br> (i.e. after the first 75% of data, ordered from smallest to largest).\n",
    "| max | the maximum data value recorded.\n",
    "\n",
    "### Example 2\n",
    "\n",
    "Describe works across all numeric columns by default. We can display descriptive information for other data types by using the parameter `include= ` . \n",
    "\n",
    "This parameter takes a list as the input; even if we’re just including one kind of data. Here we’re specifying that we want to include “object”, our text/string columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(include=[\"object\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c1ed3",
   "metadata": {},
   "source": [
    "| Summary Statistic | Description|\n",
    " |--------------------------|-----------------|\n",
    "| count | The number (count) of non missing entries in the given column.\n",
    "| unique | The number of unique variables in a column.\n",
    "| top | The most frequently occurring value.\n",
    "| freq | The frequency of the “top” value (how often it appears).\n",
    "\n",
    "If there are two or more “top” values; e.g. both most frequently occurring values that have the same frequency within the table, Python will [kind of arbitrarily](https://github.com/pandas-dev/pandas/issues/15833) choose one of them to be the top value. The link is added for general interest, you don't need to understand it.\n",
    "\n",
    "In this data there are two women and two men who share the same name. Pandas will choose one of them to display.\n",
    "\n",
    "[return to menu](#menu)\n",
    "\n",
    "<a id='range'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7b034",
   "metadata": {},
   "source": [
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195adfc",
   "metadata": {},
   "source": [
    "# Range\n",
    "\n",
    "We can also access these summary statistics individually. In most cases the name of the method is the same as the summary statistic.\n",
    "\n",
    "## min\n",
    "\n",
    "We can use `.min()` to return the minimum value in a column.\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c94f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9692c52",
   "metadata": {},
   "source": [
    "This also works for object (text) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"name\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61baa6c0",
   "metadata": {},
   "source": [
    "## max\n",
    "\n",
    "We can use `.max()` to return the maximum value in a column.\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76fc918",
   "metadata": {},
   "source": [
    "This also works for object (text) columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf64aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"name\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6dc00",
   "metadata": {},
   "source": [
    "Something important to note here is that `pandas` effectively assigns a value to each letter. This goes A-Z and **then** a-z. So a lower case \"a\" is treated as coming **after** a capital \"Z\" in Python.\n",
    "\n",
    "This is why van Melkebeke, Mr. Philemon is the maximum value in our `Titanic` Dataframe rather than Zimmerman, Mr Leo. We can handle this issue by ensuring our data is either all lower case or all upper case before finding the `.min()` or `.max()` values.\n",
    "\n",
    "### Example\n",
    "\n",
    "Here I have handled the issue by chaining the methods `.str.lower()` and `.max()` together. If I wanted to do more work with this column in future I may consider overwriting it with a lower case version (which would form part of the cleaning routine).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"name\"].str.lower().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7ecb3",
   "metadata": {},
   "source": [
    "The chaining of methods here applies left to right just as it is read, the column is selected, then the `.lower()` method is used from `str` methods, and then the `.max()` method is applied to the lower case column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676cc27",
   "metadata": {},
   "source": [
    "## Quantiles\n",
    "\n",
    "We can use `.quantile()` to find information at different points of our data.\n",
    "\n",
    "### Example\n",
    "\n",
    "Our parameter is `q= ` and then a decimal number. If we don't specify this the default behaviour is `0.5`, which returns the median (as it is the 50% quantile).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].quantile(q=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ce00d",
   "metadata": {},
   "source": [
    "If we wish to specify more than one, we pass a list to the parameter `q= `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ee457",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].quantile(q=[0, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee54c3f",
   "metadata": {},
   "source": [
    "This is a great time to mention that you don't necessary need to type a full list of numbers this way, plus the numbers we may want to use could belong to an enormous list, which is unreasonable to type by hand. This is where the range functions come in. \n",
    "\n",
    "There are two of these functions:\n",
    "\n",
    "* `range(start=, stop=, step=)` where the start parameter specifies where to start, stop specifies where to stop (which is **exclusive**! Not included) and step is how we should jump from number to number, this **must** be an integer.\n",
    "\n",
    "* `np.arange(start=, stop=, step=)` comes from the `numpy` package (`np`) and creates **a** range from the start to the stop values (where the stop is **exclusive**). However, this function allows us to step in increments of any size, including floats (or decimal numbers).\n",
    "\n",
    "Let's see two quick examples before using this with the `quantile()` function. \n",
    "\n",
    "### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a range object \n",
    "\n",
    "x = range(0, 10, 2) # Jump from 0-10 in increments of 2\n",
    "\n",
    "# Using np.arange() to obtain an array of values\n",
    "\n",
    "y = np.arange(0, 10, 0.5) # Jump from 0-10 in increments of 0.5\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28719f",
   "metadata": {},
   "source": [
    "You see here that the `range()` function gives a range object, rather than a list like structure of the values themselves, this restricts its use even further as it is less readable. It is recommended that `np.arange()` is used in most circumstances. Whilst the second output looks like a list, it is actually an **array**, a numpy specific object that is beyond the scope of this course. \n",
    "\n",
    "For more information consult this [link](https://numpy.org/doc/stable/user/absolute_beginners.html) from Numpy. In the future, there will be some **Reference Material** added to this course that introduces this data type, as it is a great piece of material to come back to when moving onto more complex causes like `Introduction to Machine Learning`. This will never be listed as Core material, so don't concern yourself too much with it. \n",
    "\n",
    "### Example 2\n",
    "\n",
    "Let's see how this function helps when finding quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae15cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that .arange() comes from the numpy package (np)\n",
    "\n",
    "\n",
    "titanic[\"fare\"].quantile(q=np.arange(start=0.0, \n",
    "                                     stop=1.1,  # Remember this is exclusive!\n",
    "                                     step=0.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abcb56",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) How old are the youngest and oldest passengers in the titanic DataFrame? \n",
    "\n",
    "(b) Print out the 20th, 40th, 60th and 80th percentiles of the fare column in the titanic DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise \n",
    "\n",
    "# (a) \n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0de2c",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='averages'></a>\n",
    "\n",
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">\n",
    "\n",
    "# Averages\n",
    "\n",
    "Now we will look at Measures of Central Tendency, often referred to as Averages. \n",
    "\n",
    "## Mean\n",
    "\n",
    "Seen briefly in the previous chapter when discussing filling in missing values, the `.mean()` method (this is the **arithmetic mean**, which corresponds to summing all values and then dividing by the  number of values there were) computes the arithmetic mean of a column.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02240cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean of the fare column\n",
    "\n",
    "titanic[\"fare\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e48e7e",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "Confirm that the value given by `.mean()` for the fare column is the same as computing it manually. \n",
    "\n",
    "Hint: You will need the `.sum()` function to compute the total of the column and the `.count()` function to compute the number of values (we will see this function in some more detail later). Remember that to compare if two objects are equal, we need to use `==`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2279e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f97711",
   "metadata": {},
   "source": [
    "An interesting observation here is the using `len()` won't work here and provide an answer that is slightly out, this is because `len()` counts all values (including nulls), whereas `.count()` only counts the non-null values (and is what is used by `.mean()` in the background).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab5597",
   "metadata": {},
   "source": [
    "## Median\n",
    "\n",
    "The `.median()` is the middle value (50th percentile) when the numbers are listed in order.\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7dca5",
   "metadata": {},
   "source": [
    "## Mode\n",
    "\n",
    "The `.mode()` is the value that occurs most frequently in the column.\n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdfe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540e9f3",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "We can also find the mode in object based columns. Here the `name` column has two modes, since both `Connolly, Miss. Kate` and `Kelly, Mr. James` appear twice in the Data Frame.\n",
    "\n",
    "Generally, when these cases appear the following terminology is used:\n",
    "\n",
    "* One mode - Unimodal\n",
    "* Two modes - Bimodal\n",
    "* Three modes - Trimodal \n",
    "\n",
    "As such, the name column is bimodal in this example. If you're wondering how we know the frequency (the number of times they each appear in the DataFrame), we will see a very useful method for this later in the chapter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705672b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"name\"].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cc76c",
   "metadata": {},
   "source": [
    "Interestingly this data isn’t duplicates! There really were two separate individuals with those names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[(titanic[\"name\"] == \"Connolly, Miss. Kate\") | (titanic[\"name\"] == \"Kelly, Mr. James\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10854bd",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='spread'></a>\n",
    "\n",
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d86c38",
   "metadata": {},
   "source": [
    "# Spread\n",
    "\n",
    "Another element of the data we often want to investigate is how spread out it is, we use Measures of Spread to do so. \n",
    "\n",
    "## Standard Deviation\n",
    "\n",
    "The standard deviation measures the spread of the data about the mean value. It shows you how much your data distribution is spread out around the mean or average.\n",
    "\n",
    "### Example\n",
    "\n",
    "We can calculate the standard deviation using the `.std()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618a399",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "Variance measures how spread out the values of a variable are in general.\n",
    "\n",
    "### Example\n",
    "\n",
    "We can calculate the variance using the `.var()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d5426",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a)(i) Find the variance and standard deviation of the `age` column in the titanic dataset.\n",
    "\n",
    "(a)(ii) Round these two values to 2 decimal places and output the values in a sentence.\n",
    "\n",
    "(b) There is a link between these two metrics, namely that the Standard Deviation is the square root of the Variance. Confirm this relationship. Hint: To use square root, we need the `np.sqrt()` function from numpy (`import numpy as np`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db81844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)(i)\n",
    "\n",
    "# (a)(ii)\n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e5bc6",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='count'></a>\n",
    "\n",
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f29eb",
   "metadata": {},
   "source": [
    "# Counting Values\n",
    "\n",
    "## Counts\n",
    "\n",
    "As we saw in the earlier exercise, we can find the number of non null values in a column using the `.count()` method. By non null values we mean values with data in them, not the missing values.\n",
    "\n",
    "As a reminder we can use either `.shape` or `len()` to find the number of rows, which for titanic is 1309 rows (this includes rows that have missing values).\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd89880",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"embarked\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60dfd3",
   "metadata": {},
   "source": [
    "As you can see `embarked` returns 1307 - so there's 2 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6152e9",
   "metadata": {},
   "source": [
    "## Null Value counts\n",
    "\n",
    "We can find how many null values we have by using the `.isnull()` method. This returns a Boolean series consisting of `True` and `False` values whether the value is null or not. \n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"age\"].isnull().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99f8fb",
   "metadata": {},
   "source": [
    "As these have numeric values behind them (`True` is 1, `False` is 0 ) we can use `.sum()` to total them and obtain the number of null values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51115da",
   "metadata": {},
   "source": [
    "In more modern versions of Pandas the method `.isna()` also exists and provides the same output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557106b5",
   "metadata": {},
   "source": [
    "### Exericse\n",
    "\n",
    "Compute the proportion of null values (a decimal between 0 and 1, equivalent to a percentage, for example 0.85 means 85%) in the `age` column. Use the `isna()` function to compute the number of null values this time.\n",
    " \n",
    "Hint: To compute this, we need to first compute the number of null values and divide by the number of values overall in the column **including the nulls!**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3376f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8aba2",
   "metadata": {},
   "source": [
    "## Value Counts\n",
    "\n",
    "We can find the frequencies of each unique value in a column, by using `.value_counts()`. This is particularly useful when applied to object columns to observe what values appear the most and least frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303345c",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) How many passengers were in each class?\n",
    "\n",
    "(b) Look in the help for `pd.Series.value_counts()` to see how you can return the values as a proportion instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a) \n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3307be9",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='other'></a>\n",
    "\n",
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf1e4a",
   "metadata": {},
   "source": [
    "# Other Summary Statistics\n",
    "\n",
    "## Sum\n",
    "\n",
    "We can use `.sum()` to add up columns of numeric data, which we saw when counting the null values. \n",
    "\n",
    "### Example 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e2288",
   "metadata": {},
   "source": [
    "The `.sum()` method comes from Pandas; there is also an inbuilt function `sum()`. However if we have null values in the column this will return us `nan`.\n",
    "\n",
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a150e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(titanic[\"fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc9314",
   "metadata": {},
   "source": [
    "## Unique\n",
    "\n",
    "We can use `.unique()` to find values that are unique in a column. This is returned as an array.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"boat\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44546543",
   "metadata": {},
   "source": [
    "## Nunique\n",
    "\n",
    "`.nunique()` can be used to find the number of unique values in a column.\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec51606",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"boat\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3cda2",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='cut'></a>\n",
    "\n",
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db18ac91",
   "metadata": {},
   "source": [
    "# Creating Size Bands\n",
    "\n",
    "## pd.cut()\n",
    "\n",
    "We can use the method `pd.cut()` to cut or “bin” our data into groups or categories. This is commonly done when creating size bands; like age bands, to create a categorical column out of a numeric one. \n",
    "\n",
    "The method `pd.cut()` takes a column of data and groups it into “bins” or categories. This column will have the data type of “category”. There’s some more information about the “category” data type [in this link]( https://pbpython.com/pandas_dtypes_cat.html).\n",
    "\n",
    "We often assign the output of `pd.cut()` to a new column. This is because we don’t want to overwrite and change the data type of the existing column.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"binned_ages\"] = pd.cut(titanic[\"age\"],\n",
    "                                bins=10)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7ccf3",
   "metadata": {},
   "source": [
    "We set the parameter `bins =` to specify the number of categories that we want. By passing an integer to this, Pandas takes the smallest value and the largest value in the column and creates the number of categories defined.\n",
    "\n",
    "We can look at our bins. Note the `(` denotes **exclusion** of that number and the `]` denotes **inclusion** of that number. \n",
    "\n",
    "### Example 1\n",
    "\n",
    "Now these are `categories` we can see there is a relationship between each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"binned_ages\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f6f16",
   "metadata": {},
   "source": [
    "We can also pass our own values to determine where the edges of the categories are, rather than allowing Python to compute these approximate ones. This could be as a list of values or a range object that we discussed before. \n",
    "\n",
    "### Example 2\n",
    "\n",
    "Note that here I am having to use the `numpy` method  `np.arange()` as there will be decimals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"binned_ages2\"]  = pd.cut(titanic[\"age\"],  # Data to cut\n",
    "                                  bins=np.arange(start=0,\n",
    "                                                 stop=(titanic[\"age\"].max() + 1) , # Remember stop is exclusive!\n",
    "                                                 step=10))\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c86e6",
   "metadata": {},
   "source": [
    "This means I don’t have to know the maximum value for the column before I write this piece of code. You can see how we can combine methods quite easily to make our life easier when performing such tasks.\n",
    "\n",
    "It is important to note that in this part of the code :\n",
    "\n",
    "`stop=(titanic[\"age\"].max() + 1)` \n",
    "\n",
    "I use brackets to enforce the order of operations. If I didn’t add 1 to the stop, the entry at my maximum value would read `NaN`, which I want to avoid.\n",
    "\n",
    "### Example 3\n",
    "\n",
    "We can also add labels to our categories. This time rather than displaying the bin edges it will display the text strings we specify.\n",
    "\n",
    "This is passed as a list to the parameter `labels=` to the `pd.cut()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9921f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"binned_ages3\"] = pd.cut(titanic[\"age\"],  # Data to cut\n",
    "                                 bins=np.arange(start=0,\n",
    "                                                        stop=(titanic[\"age\"].max() + 1),\n",
    "                                                step=10),\n",
    "                                 labels=[\"0 – 10\", \"11-20\", \" 21 – 30\",\n",
    "                                         \"31 – 40\", \"41 – 50\", \"51 – 60\",\n",
    "                                         \"61 – 70\", \"71 - 80\"])\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59a21a",
   "metadata": {},
   "source": [
    "Note these bands are approximate, e.g someone with an age of 20.2 will go into the band labelled `21-30`. Integers were chosen as it's an easier read, and most ages after 1 are whole numbers. \n",
    "\n",
    "There’s additional parameters we can set here; check the help function if there’s anything specific you need to do. You will get some more practice with this in the Case Study in Chapter 7. \n",
    "\n",
    "## pd.qcut()\n",
    "\n",
    "`pd.qcut()` is described in the documentation as a “Quantile-based discretization function”. This means that `pd.qcut()` tries to divide the data into bins of equal sizes, rather than using the numeric edges of the data to create the bins.\n",
    "\n",
    "### Example\n",
    "\n",
    "In the cell below I’m using `pd.qcut()` to cut the `age` column in to 10. This using the same data and the same number of segments as the `pd.cut()` we did at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3679f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide fare into 3 equally sized classes.\n",
    "titanic[\"age_qcut\"] = pd.qcut(titanic[\"age\"],\n",
    "                              q=10)  # q for quantiles\n",
    "\n",
    "#View the data\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6fd9eb",
   "metadata": {},
   "source": [
    "## Visual Differences between cut and qcut\n",
    "\n",
    "We can really see the difference between the two new \"cut\" columns if we visualise them. In the following, I've taken a `pd.cut()` and a `pd.qcut()` and set `bins/q = 10`.\n",
    "\n",
    "* The `pd.cut()` action on the left, cuts the range of the data into 10 bins. You can see the data is not distributed evenly between these 10 bins, but the bins are of equal size.\n",
    "\n",
    "* The `pd.qcut()` action on the right cuts the data so each of the 10 bins has roughly an equal number in each bin (edge cases in this case have made it slightly more uneven as we cannot split identical values between bins!). You can see the size of bins is not uniform, unlike the `pd.cut()` bins.\n",
    "\n",
    "![A comparison of cut and qcut](../images/comparing_cut_and_qcut.svg)\n",
    "\n",
    "### Chart Code\n",
    "\n",
    "Note that this course doesn't cover plotting, there is a **Data Visualisation in Python** course avalible on the Learning Hub. The code is provided here for information purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Charting\n",
    "\n",
    "# Import the package matplotlib - and use the magic command to show visualisations below the cell.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "# Prep The Data for Visualsation with pd.cut() \n",
    "\n",
    "titanic[\"binned_ages_2\"]  = pd.cut(titanic[\"age\"],  \n",
    "                                   bins=10,\n",
    "                                   labels=[\"0.0869 to 8.15\", \"8.16 to 16.133\", \"16.134 to 24.117\", \"24.117 to 32.1\",\n",
    "                                           \"32.2 to 40.083\", \"40.084 to 48.067\", \"48.068, 56.05\", \"56.06 to 64.033\" ,\n",
    "                                           \"64.033 to 72.017\", \"72.017, 80.0\"])\n",
    "\n",
    "# Find the value counts, set the columns in the order I want and reset the index\n",
    "\n",
    "pd_cut_values = titanic[\"binned_ages_2\"].value_counts()\n",
    "\n",
    "pd_cut_values = pd_cut_values.reindex([\"0.0869 to 8.15\", \"8.16 to 16.133\", \"16.134 to 24.117\", \"24.117 to 32.1\",\n",
    "                                       \"32.2 to 40.083\", \"40.084 to 48.067\", \"48.068, 56.05\", \"56.06 to 64.033\" , \n",
    "                                       \"64.033 to 72.017\", \"72.017, 80.0\"])\n",
    "\n",
    "pd_cut_values = pd_cut_values.reset_index()\n",
    "\n",
    "\n",
    "# Prep The Data for Visualsation using pd.qcut()\n",
    "\n",
    "titanic[\"q_cut_ages\"] = pd.qcut(titanic[\"age\"],\n",
    "                                q=10,\n",
    "                                labels=[\"0.166 to 14.0\", \"14.1 to 19.0\", \"19.1 to 22.0\", \"22.0 to 25.0\", \"25.0 to 28.0\", \n",
    "                                        \"28.1 to 31.0\", \"31.1 to 36.0\", \"36.0 to 42.0\", \"42.0, 50.0\", \"50.0 to 80.0\"])\n",
    "\n",
    "# Find the value counts and reset the index\n",
    "\n",
    "q_cut_values = titanic[\"q_cut_ages\"].value_counts()\n",
    "\n",
    "q_cut_values = q_cut_values.reindex([\"0.166 to 14.0\", \"14.1 to 19.0\", \"19.1 to 22.0\", \"22.0 to 25.0\", \"25.0 to 28.0\", \n",
    "                                     \"28.1 to 31.0\", \"31.1 to 36.0\", \"36.0 to 42.0\", \"42.0, 50.0\", \"50.0 to 80.0\"])\n",
    "\n",
    "q_cut_values = q_cut_values.reset_index()\n",
    "\n",
    "# Set up the figure and axes (which are objects!)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "#Plot Figure 1 - our pd.cut()\n",
    "\n",
    "ax1.barh(np.arange(len(pd_cut_values)), pd_cut_values[\"binned_ages_2\"], color=\"#094267ff\")\n",
    "ax1.set_xlabel(\"Frequency\")\n",
    "ax1.set_ylabel(\"Bins\")\n",
    "ax1.set_title(\"Using pd.cut() - The Frequency of Data Per Bin\")\n",
    "ax1.set_yticklabels(pd_cut_values[\"index\"])\n",
    "ax1.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Plot figure 2 - our pd.qcut()\n",
    "\n",
    "ax2.barh( np.arange(len(q_cut_values)), q_cut_values[\"q_cut_ages\"], color=\"#a4cf00ff\")\n",
    "ax2.set_xlabel(\"Frequency\")\n",
    "ax2.set_ylabel(\"Bins\")\n",
    "ax2.set_title(\"Using pd.qcut() - The Frequency of Data Per Bin\")\n",
    "ax2.set_yticklabels(q_cut_values[\"index\"])\n",
    "ax2.set_yticks([0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "# Space out the figures so the right y_label doesn't overlap!\n",
    "\n",
    "f.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# Set a Centered title to for both figures.\n",
    "\n",
    "f.suptitle(\"Comparing the distribution of data within bins using pd.cut() and pd.qcut()\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf089f0",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='agg'></a>\n",
    "\n",
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b6996",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "Aggregation means grouping data together by a particular grouping variable (of our choice) and producing a summary of one or more columns for that grouping variable. For example, what if I want to find out if the average fare paid is different for each passenger class? I could use this technique to find out. \n",
    "\n",
    "We have 3 passenger classes; 1st, 2nd and 3rd, which we can check that using the `.unique()` function as we saw earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"pclass\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83c3c5",
   "metadata": {},
   "source": [
    "We'll use the `.groupby()` method in this tutorial. Panda's also provides us with the `pd.crosstab()` and the `pd.pivot_table()` methods as well. You can find these in the **Reference Material** as they are a little more niche in their application. \n",
    "\n",
    "This function can be really useful, especially when your data are disaggregate, e.g. data about individual units of people or things, rather than by category. \n",
    "\n",
    "The method `.groupby()` allows us to aggregate by a categorical variable and summarise numerical data into a new DataFrame. It works on a very interesting principle known as **split-apply-combine**:\n",
    "\n",
    "![image showing the stages of a group by](../images/group_by.JPG)\n",
    "\n",
    "* Split is where a DataFrame is divided into a set of smaller DataFrames based on the grouping variable. \n",
    "\n",
    "* Apply is where an aggregation is applied to each of the groups to create a single row for each group in the original DataFrame (for example computing a mean).\n",
    "\n",
    "* Combine is where we bring together the aggregated DataFrame rows into a final new DataFrame.\n",
    "\n",
    "### Example 1\n",
    "\n",
    "Let's see an example of this in action, it sounds complex (and it is with what goes on behind the scenes), but the final output is much more readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_class_fare = titanic.groupby(by=\"pclass\")[\"fare\"].mean() \n",
    "\n",
    "titanic_class_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515da4d",
   "metadata": {},
   "source": [
    "I want to find if the `.mean()` value of the `Fare` was different depending where someone embarked. let's break the code down:\n",
    "\n",
    "* In the `.groupby()` method to the `by= ` parameter I pass the column I wish to group by. The column `pclass` has three values,  \"1\" , \"2\" and \"3\".\n",
    "\n",
    "* The `.groupby()` behaviour will effectively split the original DataFrame `titanic` into three new DataFrames. One with the values of `1`, one for \"2\" and one with the values of `3`. This is the **split** step.\n",
    "\n",
    "* From these new `.groupby()` DataFrames I select the column `[\"fare\"]` and apply the summary statistic `.mean()` to it. This is the **apply** step.\n",
    "\n",
    "* This is returned in the DataFrame “titanic_class_fare”, this is the **combine** step.\n",
    "\n",
    "### Example 2\n",
    "\n",
    "We can also use more complicated groupings using more than one variable, here we group first by `pclass` then `embarked`. As with many methods we discussed in earlier chapters, we must specify the column names in a list, where order is important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378cd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(by=[\"pclass\", \"embarked\"])[\"fare\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71ef15",
   "metadata": {},
   "source": [
    "To show off why order is important, see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2300ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(by=[\"embarked\", \"pclass\"])[\"fare\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74adf5",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "You can also use other summary statistics here, for example `.count()` to return the number of values. The following shows that 141 passengers embarked in Cherbourg (embarked = C) and were pclass 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(by=[\"embarked\", \"pclass\"])[\"fare\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b65afb",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "Now let's do some exercises!\n",
    "\n",
    "### Exercises\n",
    "\n",
    "(a) Group `animals` by the column `AnimalClass` and find the `.sum()` of the `IncidentNominalCost(£)` column.\n",
    "\n",
    "(b) Group `animals` by the column `Borough` and `AnimalClass` and find the `.mean()` of the `PumpHoursTotal` column.\n",
    "\n",
    "(c) Reverse the order of the grouping in (b) and observe the differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n",
    "\n",
    "# (c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4df09",
   "metadata": {},
   "source": [
    "## Multiple Aggregation\n",
    "\n",
    "If we want to return more than one aggregation at once to the columns we've selected, there is the `.agg()` method. This takes a dictionary where the key is our column and the value is the aggregation method we wish to apply as a string.\n",
    "\n",
    "These aggfuncs are slightly different to what we’ve seen, but are straightforward like “sum”, ”count”, ”mean” etc. Let's first see it with one aggregation before building up to two. \n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d698bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "animalclass_sum = animals.groupby(by=\"AnimalClass\").agg({\"IncidentNominalCost(£)\": \"sum\",\n",
    "                                                         \"PumpHoursTotal\": \"mean\"})\n",
    "\n",
    "animalclass_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee3e4f",
   "metadata": {},
   "source": [
    "If we want to apply more than one aggregation to a column we can pass a list to the values of the dictionary. This requires us to use the numpy methods which are very similar to the methods we have used previously, so `np.sum` , `np.mean` etc.\n",
    "\n",
    "### Example 2\n",
    "\n",
    "Here we will output the sum and the mean for `IncidentNominalCost(£)` and the mean for `PumpHoursTotal`. Notice that since there is only one method applied in the second case, we can just use the standard mean method, it is only when we use lists that numpy comes into play.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "animalclass_sum = animals.groupby(by=\"AnimalClass\").agg({\"IncidentNominalCost(£)\": [np.sum, np.mean],\n",
    "                                                         \"PumpHoursTotal\": \"mean\"})\n",
    "\n",
    "animalclass_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649ba23",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Group the `animals` dataset by the variable `Borough` and obtain the following summary statistics:\n",
    "\n",
    "* The variance and standard deviation of the `IncidentNominalCost(£)` column.\n",
    "\n",
    "* The mean of the `PumpCount` column.\n",
    "\n",
    "* The sum of the `PumpHoursTotal` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a10d03",
   "metadata": {},
   "source": [
    "In later versions of Pandas (from 0.25.0) named aggregation also exists. [The help guide can be found here]( https://pandas-docs.github.io/pandas-docs-travis/user_guide/groupby.html#named-aggregation)\n",
    "\n",
    "Note that these DataFrames displayed when you run the code look a little different to the ones I have displayed here. You will see that in yours, the index is our grouping categories. We can use our `.reset_index()` method here too, or use `as_index = False`. There are a few reasons we might do this, including making visualisation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1591e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_dropped_index = titanic.groupby(by=[\"embarked\", \"pclass\"], as_index= False)[\"fare\"].count()\n",
    "group_by_dropped_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5de70",
   "metadata": {},
   "source": [
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e8364",
   "metadata": {},
   "source": [
    "<a id='END'></a>\n",
    "\n",
    "# Chapter Summary\n",
    "\n",
    "Excellent job, you have completed Chapter 6 of the Introduction to Python course. There is only one chapter left before you complete **Core Part 1** of the course! Absolutely amazing aggregating!\n",
    "\n",
    "Chapter 7 will feature a structured end of course exercise, that tests you on everything you have learned from Chapter 3 to Chapter 6, with a new dataset we have yet to explore, the **schools** dataset. \n",
    "\n",
    "\n",
    "[return to menu](#menu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
