{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee178c6",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.25\"> \n",
    "\n",
    "![Analysis Function and DSC Logo](../images/AF_DSC_banner.png)\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.25\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1379a",
   "metadata": {},
   "source": [
    "# Introduction to Python\n",
    "\n",
    "## Chapter 4 - Working With DataFrames\n",
    "\n",
    "*Chapter Overview and Learning Objectives*:\n",
    "\n",
    "* [Packages and Datasets](#packages)\n",
    "\n",
    "\n",
    "* [Exploring Datasets](#exploring)\n",
    "    - Quick Previews\n",
    "    - Size\n",
    "    - Data Types\n",
    "    - Column Names\n",
    "\n",
    "\n",
    "* [Sorting Data](#sorting)\n",
    " \n",
    "\n",
    "* [Subsetting Data](#subsetting)\n",
    "    - Selecting Single Columns\n",
    "    - Selecting Multiple Columns\n",
    "    \n",
    "    \n",
    "* [Filtering](#filter)    \n",
    "    - Single Conditional Filtering\n",
    "    - Multiple Conditional Filtering\n",
    "\n",
    "\n",
    "* [Deriving New Columns](#new_columns)\n",
    "    - Constant Values\n",
    "    - Numeric Values\n",
    "    - Boolean and Binary Values\n",
    "    - Mapping new values\n",
    "    - Deleting columns\n",
    "    \n",
    "    \n",
    "* [Merging Data](#merge)\n",
    "    - About Merging\n",
    "    - Merging using Pandas\n",
    "    - Union joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853f0d2",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae94b82",
   "metadata": {},
   "source": [
    "<a id='packages'></a>\n",
    "\n",
    "# Packages and Datasets\n",
    "\n",
    "## Packages\n",
    "As a reminder, we should always import our packages at the top of our script. In this chapter (and for the rest of the course) we will use `pandas`, and give it the alias `pd`.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Import Pandas and give it the alias pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db66ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2be2c",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "Good practice also dictates that we import our datasets at the top of our script too, following the import of packages.\n",
    "\n",
    "In this session we’ll be using:\n",
    "\n",
    "* animals - animals.csv \n",
    "* titanic - titanic.xlsx \n",
    "* joining_data1 - joining_data1.csv \n",
    "* joining_data2 - joining_data2.csv \n",
    "* union_join_data - union_data.csv \n",
    "* marvel_left - joining_exercise1.csv \n",
    "* marvel_right - joining_exercise2.csv \n",
    "\n",
    "These are all straight forward data imports with no additional parameters required. This is a good test of the techniques covered in Chapter 3.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Load in these datasets listed above\n",
    "\n",
    "You can check your variables are loaded by using `%whos` in Jupyter. In Spyder or other IDE's they should appear in your variable explorer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c765097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4759bd",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">\n",
    "\n",
    "<a id='exploring'></a>\n",
    "\n",
    "# Exploring Datasets\n",
    "\n",
    "Before you start working with a dataset it is important to examine it. For example:\n",
    "\n",
    "* Do the values look how you would expect?\n",
    "* Does the data have the right number of rows and columns? \n",
    "* Do the columns have your expected data types?\n",
    "* Is your data [clean?](https://en.wikipedia.org/wiki/Data_cleansing)\n",
    "\n",
    "In this section we’ll look at various ways of exploring our data, with the aim of answering the above questions.\n",
    "\n",
    "In chapter 5 we will look at how we can clean our data. When working with data, cleaning is normally a step we’d do first. Those concepts are a little more complicated; and we like to establish a good base knowledge of how Python works first. For these sessions we’ll be using data that has already been cleaned to make it easy to handle.\n",
    "\n",
    "## Quick Previews\n",
    "\n",
    "In the last section we looked at three methods of quickly inspecting our dataframes.\n",
    "\n",
    "* `.head()`  - Top 5 rows (can be altered with parameter n =)\n",
    "* `.tail()`  - Bottom 5 Rows (can be altered with paramter n =)\n",
    "* `.sample()` - 1 Randomly sampled row.\n",
    "\n",
    "We use these because we do not always want Jupyter Notebooks to print out large datasets; we just want to check that certain operations have worked on a smaller amount of data.\n",
    "\n",
    "To review, we can modify how many rows are returned by putting a number within the round brackets. The number in the round brackets is known as an argument. `.head()` and `.tail()` have a default argument of 5; if we don't pass an argument that default behaviour is used. \n",
    "\n",
    "You may recall that we mentioned this parameter is 'n =', but we need not specify the name, just the argument. Why is this? This is because Python knows what parameter we are giving an argument for when specifying the integer to `.head()` or `.tail()`. \n",
    "\n",
    "However, don't always rely on this, as order comes into play when functions/methods have a large number of parameters (and particularly multiple ones of the same type, integers etc). As such, it is good practice to use the name of the parameter in most cases.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.head(3)\n",
    "\n",
    "# Best Practice\n",
    "# animals.head(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa4488",
   "metadata": {},
   "source": [
    "If you run just `animals`, you may notice that Jupyter does not display all of the rows in our DataFrame.\n",
    "\n",
    "![image showing rows of a DataFrame, it displays the first 30 rows then some elipsis and the last 30 rows](../images/sort_missing_rows.PNG)\n",
    "\n",
    "Instead it represents these rows using three dots, `…` (ellipsis) symbol. You may also see this with columns. This often happens in large datasets; and helps to save computational power. This is similar to the max print option in Spyder and other IDEs.\n",
    "\n",
    "While there are various ways of changing this setting with Jupyter (Stack Overflow has several answers), if you are regularly using large DataFrames, and wish to inspect all rows you may wish to use VSCode or another IDE, since many of these have in built data viewers (which allow us to view the whole dataset). \n",
    "\n",
    "We can also use `.info()` this gives us information about:\n",
    "\n",
    "* The class of the object – a `pandas` DataFrame\n",
    "* The range (or length of our index), a.k.a the number of rows\n",
    "* How many columns we have\n",
    "* The column names\n",
    "* The number of non-null entries (a.k.a without missing values)\n",
    "* The data type of the column\n",
    "* The number of columns of each data type.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd52cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf8d52",
   "metadata": {},
   "source": [
    "## Size\n",
    "\n",
    "Knowing the size of our DataFrame is also useful (a.k.a the number of rows and columns), separately to what `.info()` gives us. Often we want to save these elements to variables and this is difficult with that method and as such, we use other methods to draw out this information for further analysis. \n",
    "\n",
    "### Example\n",
    "\n",
    "`.shape` provides us a tuple with the dimensions of the object, in the form (number of rows, number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce29061",
   "metadata": {},
   "source": [
    "Notice this is the first example of an attribute of the DataFrame rather than a method, so doesn't require the round brackets at the end of its call. We talk a bit more about the similarities and differences between functions, methods and attributes in chapter 2. Feel free to review that section if you are stuck.\n",
    "\n",
    "We can use our indexing brackets (also discussed at length in chapter 2) to return an item in this tuple, for example the number rows at index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca82650",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d8627",
   "metadata": {},
   "source": [
    "And the number of columns at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b897ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb309a",
   "metadata": {},
   "source": [
    "As an aside:\n",
    "\n",
    "Because `.shape` returns us a tuple we can assign each of these to it’s own variable. To do this we give our variable names in the order of the tuple output, separated by a comma before our assignment operator (=).\n",
    "\n",
    "### Example\n",
    "\n",
    "Our tuple outputs rows first then columns, so we give our variables as `nrow` and `ncol`. This is also a great chance to show off multi-variable assignment introduced in chapter 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a91188",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow, ncol = animals.shape\n",
    "\n",
    "print(\"There are\", nrow, \"rows, and\", ncol, \"columns in the animals DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb354c89",
   "metadata": {},
   "source": [
    "Of course, you can always do this separately without multi-variable assignment as below, but that way is certainly the most efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5115a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = animals.shape[0]\n",
    "ncol = animals.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace8b7a",
   "metadata": {},
   "source": [
    "We can also use the inbuilt `len()` function to find the **len**gth. This will return us the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93448b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a06a00",
   "metadata": {},
   "source": [
    "We can also modify this to return us the number of columns as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de090131",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(animals.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b8795",
   "metadata": {},
   "source": [
    "Note that the .columns **attribute** is also very useful, returning something called an Index object containing the ordered column names of the pandas object. Returning the length of such an object gives us the number of values (a.k.a the number of columns). \n",
    "\n",
    "More info on this datatype is available [here](https://pandas.pydata.org/docs/reference/indexing.html), but I would suggest returning to this later as **reference** material. \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Look at the dimensions of the `titanic` DataFrame.\n",
    "\n",
    "(a) Use shape to return the tuple of rows and columns.\n",
    "\n",
    "(b) Use multi-variable assignment to obtain the rows and columns as variables.\n",
    "\n",
    "(c) Print the results from (b) in a suitable sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n",
    "\n",
    "# (c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6136e",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0a526",
   "metadata": {},
   "source": [
    "# Data Types\n",
    "\n",
    "It is also important to check the data types when we bring in data. If you’ve worked with other analytical software before you’ll know that sometimes data doesn’t come in as we would expect.\n",
    "\n",
    "We do this using `.dtypes`, another very useful attribute (delivering on that promise that we will use attributes as well as methods!).\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c312c",
   "metadata": {},
   "source": [
    "We have some of the data types we’re seen before\n",
    "\n",
    "* **int** represents integers; our whole numbers\n",
    "\t* CalYear (Calendar Year) is column of whole numbers\n",
    "    \n",
    "    \n",
    "* **float** represents ‘floating point’ numbers or decimals\n",
    "\t* IncidentNominalCost(£) (The financial cost of each incident) is a decimal number.\n",
    "\n",
    "\n",
    "* **object** or **O**  here represents what we’ve been calling *string* data so far, in that they are text values\n",
    "\t* AnimalClass (The kind of animal) is a text based value.\n",
    "\n",
    "We may also see\n",
    "\n",
    "* **bool** - representing Boolean values; our True and False\n",
    "* **datetime** - date and time values\n",
    "* **category** - a special `pandas` datatype for categorical or factor variables (see Chapter 7 for more info, this is **reference** material)\n",
    "\n",
    "You may notice that some categories have not come in quite how we would expect.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['DateTimeOfCall'].dtypes\n",
    "\n",
    "# This is how we select a single column; we'll cover this later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db412891",
   "metadata": {},
   "source": [
    "DateTimeOfCall` has come in as an `object` or text value; when it should be `datetime`. This is extremely common with dates and times in a variety of software; not just Python! \n",
    "\n",
    "![An XKCD comic showing a variety of date formats, ranging from standardised to ridiculous. The comic states that the correct way to write numeric dates is following ISO standards with a 4 number year, two digit month and two digit date, seperated by hypens. ](../images/iso_8601.png)\n",
    "\n",
    "<center> <a href = \"https://xkcd.com/1179/\"> Source: xkcd ISO 8601</a> </center>\n",
    "\n",
    "Python will often choose an `object` data type for columns: if there’s any ambiguity over the data type. This is because this data type retains all the characteristics of the data and allows us to make the choice about how to process it.\n",
    "\n",
    "For example, the date 01/11/19 could be interpreted as either:\n",
    "\n",
    "* 1st November 2019\n",
    "* 11th January 2019\n",
    "* 19th November 2001 \n",
    "\n",
    "depending on region (which makes the most sense to you?).\n",
    "\n",
    "Since we don’t look at handling date and time data in this course; we’ll leave these columns alone for now. This is a perfect time to reference the **Dates and Times in Python** course on the Learning Hub! This is a recommended follow up to the Introduction to Python course. \n",
    "\n",
    "For an overview that is much less in-depth than that course, the following resource is available:\n",
    "\n",
    "[This Geeks for Geeks tutorial link]( https://www.geeksforgeeks.org/python-working-with-date-and-time-using-pandas/) is a tutorial for handling dates and times using `pandas`.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Look at the data types of the `titanic` DataFrame.\n",
    "\n",
    "Are there any values you didn't expect to see?\n",
    "\n",
    "You can check the Data Dictionary (an explanation of each column) [here](https://www.kaggle.com/c/titanic/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43643139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# Type some of your thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08dd7b",
   "metadata": {},
   "source": [
    "## Column Names\n",
    "\n",
    "It is important to know what your columns are called because in Python we commonly select our columns by name. It is also key to know how they are constructed (lower case, snake case etc) as Python is case sensitive. \n",
    "\n",
    "### Example\n",
    "\n",
    "First we give the DataFrame name then the name of our column, in quotes, inside square brackets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92151af",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['AnimalClass']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d224e3",
   "metadata": {},
   "source": [
    "We can then add a method to the end, for example`.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['AnimalClass'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd317330",
   "metadata": {},
   "source": [
    "While Python can handle column names with spaces, symbols and irregular capitalization; it is often easier to clean them. We’ll have a look at how to do this in Chapter 5.\n",
    "\n",
    "### Example\n",
    "\n",
    "As a reminder, We can access our columns by using the `.columns` attribute to return an Index datatype filled with the column names. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53c19b",
   "metadata": {},
   "source": [
    "It would be nice to display them as a list to make the object easier to work with, so we can add (or **chain**) the method `.tolist()` on the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075472f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ccae9f",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) Look at the column names of the `titanic` DataFrame and convert them to a list, giving it an appropriate variable name.\n",
    "\n",
    "(b) Use indexing to return the column name 'embarked'.\n",
    "\n",
    "(c) Use negative indexing to return the list without 'boat'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n",
    "\n",
    "# (c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e0fbe",
   "metadata": {},
   "source": [
    "We can also use Jupyter’s auto complete feature to help us when accessing the names of our columns. Copy the cell below place your cursor after the H and hit tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['H']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b6e6e",
   "metadata": {},
   "source": [
    "You’ll see that the auto complete option gives us the name of our `HourlyNominalCost(£)` column. This can be a really useful shortcut when we’re writing our code, circumventing the need to type out full column names.\n",
    "\n",
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9adfad",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80406768",
   "metadata": {},
   "source": [
    "# Sorting Data\n",
    "\n",
    "Our data is displayed in the same order as the source data, which means that we may want to sort our data, based on specific columns.\n",
    "\n",
    "### Example\n",
    "To do this we use the method `.sort_values(by=\"column name\")`. When transforming data like this, we want to assign the new object as we don't want to re-type this process each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70119bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_sorted = animals.sort_values(by=\"IncidentNominalCost(£)\")\n",
    "animals_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9a360",
   "metadata": {},
   "source": [
    "There are additional arguments we can set, for example, by default the values are sorted in ascending order, by changing `ascending=` to `ascending=False` we can sort in descending order instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_sorted = animals.sort_values(by=\"IncidentNominalCost(£)\", ascending=False)\n",
    "animals_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d837e5d",
   "metadata": {},
   "source": [
    "We can also sort by more than one column, but we can't just type out the column names in succession to the `.sort_values()` method. We must include them in a list instead, where order is important. \n",
    "\n",
    "### Example\n",
    "\n",
    "Here we are sorting by `\"IncidentNominalCost(£)\"`; and then by `\"AnimalClass\"`. Notice object (text/string) columns are sorted by *alphabetical* order. The reason order is important is because it creates a dependence, namely that sorting by the second column is entirely dependent on the sorting of the first column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_sorted = animals.sort_values(by=[\"IncidentNominalCost(£)\", \"AnimalClass\"])\n",
    "animals_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345ebdf",
   "metadata": {},
   "source": [
    "When sorting more than one column, it’s best to specify `ascending= ` as a list as well, to improve the readability and accessibility of our code. This list is in the same order as our columns and as such `.sort_values()` will apply column wise (first column, ascending, second column, descending etc).\n",
    "\n",
    "Some versions of Pandas will sort both columns as descending if we just supply `ascending = False` ; however some won’t, so it’s better to be clear about what we want to do. By using a list I also have finer control in that I could have one in ascending order, and one in descending order if I wished.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d921e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_sorted_desc = animals.sort_values(by=[\"IncidentNominalCost(£)\", \"AnimalClass\"], \n",
    "                                          ascending=[False, False])\n",
    "\n",
    "animals_sorted_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d85061",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) Sort the `titanic` DataFrame by the `age` column in descending order, name it `titanic_sorted`.\n",
    "\n",
    "(b) Sort the `titanic` DataFrame by the `age` **then** `sex` columns, both in ascending order. \n",
    "\n",
    "(c) Using (b), pick out the sex and of the youngest person on board the titanic. \n",
    "\n",
    "(d) Sort the `titanic` DataFrame by ascending `fare` **then** descending `age`, naming it appropriately.\n",
    "\n",
    "(e) Use your answer to part (d) to identify the oldest person who paid the least fare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a50f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n",
    "\n",
    "# (c)\n",
    "\n",
    "# (d)\n",
    "\n",
    "# (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e4ca5",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440b579",
   "metadata": {},
   "source": [
    "# Revisiting parameters and arguments \n",
    "\n",
    "I mentioned earlier that not including parameter names can sometimes confuse Python when it comes to the order in which they can be specified for larger functions. Now we will see this in practice. \n",
    "\n",
    "## Important Example\n",
    "\n",
    "Parameters are key words that tell python what the following argument relates to. We have two in the code below:\n",
    "\n",
    "* `by= ` is a parameter and the string representing the column `\"IncidentNominalCost(£)\"` is the argument.\n",
    "\n",
    "* `ascending= ` is a parameter and the Boolean value `False` is the argument\n",
    "\n",
    "If we don’t specify parameters Python will assume our arguments are in the order specified in the Signature (press `shift + tab` with your cursor in `.sort_values()` to see this), and because of this the code below won’t work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will give us an error!\n",
    "\n",
    "# After you've tried it, you may want to comment it out!\n",
    "\n",
    "animals_sorted = animals.sort_values(\"IncidentNominalCost(£)\", False)\n",
    "\n",
    "animals_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b430cb7",
   "metadata": {},
   "source": [
    "Our first argument `IncidentNominalCost(£)` maps directly to the `by=` parameter as expected. However, Python assumes the second argument `False` relates to the `axis = ` parameter; which in some versions isn't a valid argument, and in some pandas versions is treated effectively as `axis =0`.\n",
    "\n",
    "It is personal preference if you use parameters before your arguments. It is considered good practice, and can make your code more readable, especially to new coders. We would strongly advise doing so.\n",
    "\n",
    "As a bonus when you use parameters with your arguments you can pass them in any order as Python no longer relies on it being a positional based argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_sorted = animals.sort_values(ascending=False, by=\"IncidentNominalCost(£)\")\n",
    "animals_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c254595",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='subsetting'></a>\n",
    "\n",
    "# Subsetting\n",
    "\n",
    "## Selecting Single Columns\n",
    "\n",
    "Sometimes we will want to work with smaller “cut down” DataFrames that contain fewer columns. As we saw earlier the simplest way to select a column from a DataFrame is to use the name of the column in the indexing brackets []. \n",
    "\n",
    "### Example\n",
    "\n",
    "Here I am creating a new Series called ‘animal_grp_parent’ using the ‘AnimalGroupParent’ column from the animals DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcefdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_grp_parent = animals['AnimalGroupParent']\n",
    "\n",
    "animal_grp_parent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b87200",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) Select the `fare` column from the `titanic` DataFrame and name it `titanic_fare`.\n",
    "\n",
    "(b) Randomly Sample 12 rows from the `titanic_fare` object you created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb81576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efab750",
   "metadata": {},
   "source": [
    "## Selecting Multiple Columns\n",
    "\n",
    "### Example\n",
    "\n",
    "Similarly as with **sorting** by multiple columns, we can select multiple columns by providing them in a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41471c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns\n",
    "my_list_of_columns = [ \"DateTimeOfCall\", \"AnimalGroupParent\", \"IncidentNominalCost(£)\"]\n",
    "\n",
    "# Pass that list to my indexing brackets, creating a dataframe\n",
    "animal_small_df = animals[my_list_of_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea02d4f",
   "metadata": {},
   "source": [
    "We can, however do this in one step by using two sets of square brackets next to each other. It’s important to realise that they are doing two separate roles:\n",
    "\n",
    "* Our first set is selecting or indexing from the animals DataFrame.\n",
    "* Our second set is creating a list of our columns we wish to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the same result as the cell above.\n",
    "animal_small_df = animals[[ \"DateTimeOfCall\", \"AnimalGroupParent\", \"IncidentNominalCost(£)\"]]\n",
    "animal_small_df.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113825",
   "metadata": {},
   "source": [
    "Two important things to note are the following:\n",
    "\n",
    "* When we return one column we get a Series object (as DataFrames are collections of Series objects)\n",
    "\n",
    "* When we return more than one column we get a DataFrame.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "(a) Select the `name, sex, age` and `survived` column from the `titanic` DataFrame, naming it accordingly.\n",
    "\n",
    "(b) Create two sub DataFrames from your answer to part (a), one containing `sex` and `age` and another containing `name` and `survived`, naming them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af50f5",
   "metadata": {},
   "source": [
    "Note that you may see people selecting columns using `dataframe.column_name`, which is a legal practice, but certainly not a recommended one! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2643552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will work - but is not good practice!\n",
    "\n",
    "titanic.sex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda66a8",
   "metadata": {},
   "source": [
    "We don’t recommend this because it looks too much like an attribute or method. This also won’t work if you had a column that was something like `mean` as Python can’t determine if you mean the column `mean` or the method `.mean()`. \n",
    "\n",
    "There’s no ambiguity with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[“column”]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12b0b9",
   "metadata": {},
   "source": [
    "which is why we will always recommend it over the `dataframe.column_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c4a72",
   "metadata": {},
   "source": [
    "# Selecting on data type\n",
    "\n",
    "We can also use the method `.select_dtypes()` if we want to include or exclude specific kinds of data from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ad542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the object columns\n",
    "animal_object_cols = animals.select_dtypes(include=[\"object\"])\n",
    "\n",
    "# Return the top of the animal columns\n",
    "\n",
    "animal_object_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52441e8b",
   "metadata": {},
   "source": [
    "We must specify our include data types as a list here, even if we’re just specifying one value. It’s just the way this function was written (it will tell you this in the help documentation).\n",
    "\n",
    "* “object” includes our string columns, I could also use \"O\" here.\n",
    "* \"float64” and “int64” will select floating point numbers and integer numbers respectively.\n",
    "* If you have the numpy package loaded (`import numpy as np`) you can use np.number (no quotes) to return numerical data.\n",
    "\n",
    "You can even use the parameter `exclude=` which may be easier if you wish to omit just one data type. \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Create a new DataFrame `titanic_int_no_float` where we include all integer columns, but exclude all float columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22690b70",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8d41e",
   "metadata": {},
   "source": [
    "[return to menu](#menu)\n",
    "\n",
    "<a id='filter'></a>\n",
    "\n",
    "# Filtering\n",
    "\n",
    "We can achieve really simple filtering by passing a range to the DataFrame indexer.\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92017c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c552b",
   "metadata": {},
   "source": [
    "Which returns us the same rows as `.head()`. We can however modify this to return any range of rows within the DataFrame we like - for example the middle of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f389605",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals[200:210]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c758aef",
   "metadata": {},
   "source": [
    "However, we can do more involved, conditional filtering using `pandas`, which is one of the key processes for any Data Analysis task.\n",
    "\n",
    "## Single Conditional Filtering\n",
    "\n",
    "Pandas filters data in a two step process.\n",
    "\n",
    "1.\tIt creates a `mask` that specifies inclusion or exclusion for each row in the DataFrame.\n",
    "2.\tApply the mask on to the DataFrame to return the subset of rows that are included.\n",
    "\n",
    "In the code below I will create a few simple DataFrames to illustrate my point. Don’t worry too much about how these bits of code works; as previously mentioned you’ll often be working with much larger DataFrames that you’ll load in using one of the `pd.read_` commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple DataFrame to look at this in practice\n",
    "# Again, you don't need to worry about how this works\n",
    "\n",
    "cat_dog = pd.DataFrame({\"animal\": [\"Cat\", \"Cat\", \"Dog\", \"Cat\"] , \n",
    "                        \"name\": [\"Catalie Portman\",\"Pico de Gato\", \"Chewbarka\", \"Sir Isaac Mewton\"]})\n",
    "\n",
    "# Print out the DataFrame\n",
    "\n",
    "cat_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c366e9e",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "I want to filter so I just have ‘Cat’ Rows.\n",
    "\n",
    "My **condition** can be written like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cat_dog['animal'] == 'Cat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd389cf0",
   "metadata": {},
   "source": [
    "* I am assigning my output to the variable `mask` with the single = sign\n",
    "* The column I want to look for values in is `\"animal\"` from the `catdog` Dataframe - `catdog[\"animal\"]`\n",
    "* From that column I want to find values that meet my condition – I state this with the double equals `==`\n",
    "* Finally I am telling Pandas what value I want to find; a string containing “Cat”\n",
    "\n",
    "If we run the cell we can see the output is a Boolean Series, our True and False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me to see the Series of Boolean values\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b609d",
   "metadata": {},
   "source": [
    "Just to make things clearer, Here I’ve added this series as a new column on our `cat_dog` DataFrame to demonstrate.\n",
    "\n",
    "|   | animal  |       name      | included |\n",
    "|:-:|:-------:|:---------------:|----------|\n",
    "| 0 |   Cat   | Catalie Portman | True     |\n",
    "| 1 |   Cat   |   Pico de Gato  | True     |\n",
    "| 2 |   Dog   |    Chewbarka    | False    |\n",
    "| 3 |   Cat   |   Sir Isaac Mewton   | True     |\n",
    "\n",
    "We can see where the value in the `animal` column was `\"Cat\"`; the `mask` column is `True`. Where the value was not cat (e.g `\"Dog\"`) the `mask` column is `False`. However I want to return just the rows where the value in `mask` was `True`.\n",
    "\n",
    "To do this we apply the `mask` variable on to the `cat_dog` Dataframe using our indexing or selection brackets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b673688",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_cats = cat_dog[mask]\n",
    "just_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a615b6",
   "metadata": {},
   "source": [
    "This will only return the rows where our **conditional filter** equated to `True`.\n",
    "\n",
    "This seems a little long but thankfully, rather than create and apply a mask separately we can do the whole filter operation in one step. We teach it this way to break down the process into component parts, before wrapping it up in a one line bow. \n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_cats = cat_dog[cat_dog['animal'] == \"Cat\"]\n",
    "just_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d00c4",
   "metadata": {},
   "source": [
    "You’ll notice the cell with the “Dog” value has been dropped. \n",
    "\n",
    "You’ll also notice that our index has not changed. You will sometimes want to reset the index after filtering to restore it to sequential integers starting at 0 as this can cause some problems in certain circumstances.\n",
    "\n",
    "### Example\n",
    "\n",
    "You can do this like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_cats.reset_index(drop=True, inplace=True)\n",
    "just_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ca032",
   "metadata": {},
   "source": [
    "* By default the previous column index is put in as a new column. By using `drop=True` we can remove this behaviour.\n",
    "\n",
    "* `inplace=True` updates the DataFrame in place and is an alternative to overwriting the data with `just_cats = just_cats.reset_index(drop=True) `\n",
    "\n",
    "## Other Comparison Operators \n",
    "\n",
    "We have seen the equivalence sign `==` thus far, but there are other very useful operators we can utilise when conditional filtering:\n",
    "   \n",
    "| Symbol | Meaning|   \n",
    "|------------|------------|\n",
    "| ==       | Is equivalent to|\n",
    "| !=| Does not equal|\n",
    "|> |Greater than|\n",
    "|>=| Greater than or equivalent too|\n",
    "|< |Less than|\n",
    "|<= |Less than or equivalent too|\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's use our animals **DataFrame**  to find the rows where `IncidentNominalCost(£)` is over £1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here we're using the animals DataFrame\n",
    "\n",
    "cost_over_1k = animals[animals['IncidentNominalCost(£)'] > 1000]\n",
    "cost_over_1k.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638958d",
   "metadata": {},
   "source": [
    "Here we have done the following:\n",
    "\n",
    "* Assigned a new name `cost_over_1k` which will hold our output\n",
    "* Give our DataFrame name, and our indexing or selection brackets:  `animals[]`\n",
    "* The column we want to look for values in is ”IncidentNominalCost” from the Animals Dataframe `animals[‘IncidentNominalCost(£)’]`\n",
    "* The condition I want is ` > 1000` , greater than a thousand. As this is a numeric column I can just specify the number.\n",
    "* Printing out the variable, using `.sample(6)` method to display 6 rows of the new DataFrame.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "(a) Filter the `titanic` DataFrame by `sex`, returning only the rows where this is `female`. Name this something appropriate\n",
    "\n",
    "(b) Filter the `titanic` DataFrame to return the rows where the passenger age is smaller than 40 (It is useful to practice these without the exact columns to filter by given). \n",
    "\n",
    "(c) Filter the `titanic` DataFrame, returning only the rows where the fare paid is at least £30.50 (Hint: which operator would 'at least' correspond to?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eaeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n",
    "\n",
    "# (c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ce5aa",
   "metadata": {},
   "source": [
    "## Multiple Conditional Filtering\n",
    "\n",
    "Just as we can filter by one condition we can also filter by multiple conditions. Let’s add in a new column, representing age to the `cat_dog` DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple DataFrame to look at this in practice\n",
    "# Again, we don't need to worry about how we do this!\n",
    "\n",
    "cat_dog = pd.DataFrame({\"animal\": [\"Cat\", \"Cat\", \"Dog\", \"Cat\", \"Dog\"], \n",
    "                        \"name\": [\"Catalie Portman\",\"Pico de Gato\", \"Chewbarka\", \"Sir Isaac Mewton\", \"K9\"],\n",
    "                        \"age\": [3, 5, 1, 7, 11]}, \n",
    "                       columns=[\"name\", \"animal\", \"age\"])\n",
    "\n",
    "\n",
    "# Print out the DataFrame\n",
    "\n",
    "cat_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb1f35",
   "metadata": {},
   "source": [
    "When we want to filter on more than one condition, we have to consider how those conditions relate to each other in terms of what is included and what is excluded from the final filtering. \n",
    "\n",
    "* AND relationships use the & symbol (Shift and 7 on the keyboard) and require **both** or **all** conditions to evaluate to `True`.\n",
    "\n",
    "* OR relationships use the | symbol (Shift and &124;) and require **one** of the conditions to evaluate to `True`\n",
    "\n",
    "Below is a “Truth table” that can be handy as a look up.\n",
    "\n",
    "\n",
    "| Condition 1 | Condition 2  | & (AND) Equates to |  &#124; (OR) Equates to |\n",
    "|:-----------:|:------------:|:------------------:|:------------------:|\n",
    "|     True    |     True     |        True        |        True        |\n",
    "|     True    |     False    |        False       |        True        |\n",
    "|    False    |     True     |        False       |        True        |\n",
    "|    False    |     False    |        False       |        False       |\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "Now that we have an age column, we can now select all Cats that are older than 4. Again, in this example we will create a mask so we can see what Boolean values are happening behind the scenes, but in the exercises we will do this in one line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create my mask\n",
    "mask = (cat_dog['animal'] == \"Cat\") & (cat_dog['age'] > 4)\n",
    "\n",
    "# have a look at the mask\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68915de4",
   "metadata": {},
   "source": [
    "This is quite overwhelming upon first viewing, let's break it down a little bit!\n",
    "\n",
    "* I am assigning my output to the variable `mask` with a single = sign.\n",
    "\n",
    "* My first conditional statement:\n",
    "    * Has round brackets surrounding it `(`\n",
    "    * The first column I want to look for values in is `\"animal\"` from the `catdog` Dataframe - `catdog[“animal”]`\n",
    "    * From that column I want to find values that meet my condition, which I state with the double equals `==`\n",
    "    * Finally I am telling `pandas` what value I want to find; a string containing “Cat”\n",
    "    * My first condition complete I close my round brackets `)`\n",
    "    \n",
    "* I use a symbol to represent the relationship between my conditions. Here an ampersand - `&` (Shift and 7) is used to represent `AND`\n",
    "\n",
    "* My second conditional statement:\n",
    "    * Has round brackets surrounding it `(`\n",
    "    * The first column I want to look for values in is `\"age\"` from the `catdog` Dataframe - `catdog[“age”]`\n",
    "    * From that column I want to find values that are greater than my condition, which I state with the  `>`\n",
    "    * Finally I am telling Pandas what value I want to find; an int 4\n",
    "    * My second condition complete I close my round brackets `)`\n",
    "    \n",
    "    \n",
    "Let's look at the `mask` values alongside the DataFrame:\n",
    "\n",
    "|   | animal  |       name      | age | included |\n",
    "|:-:|:-------:|:---------------:|-----|----------|\n",
    "| 0 |   Cat   | Catalie Portman | 3   | False     |\n",
    "| 1 |   Cat   |   Pico de Gato  | 5   | True     |\n",
    "| 2 |   Dog   |    Chewbarka    | 1   | False    |\n",
    "| 3 |   Cat   |   Sir Isaac Mewton   | 7   | True     |\n",
    "| 4 | Dog     | K9              | 11  | False     |\n",
    "\n",
    "\n",
    "And when we apply the mask to the DataFrame we can see the filtered Dataframe - with only Cats over 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fede050",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (cat_dog['animal'] == \"Cat\") & (cat_dog['age'] > 4)\n",
    "\n",
    "cats_over_4 = cat_dog[mask]\n",
    "cats_over_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3af231",
   "metadata": {},
   "source": [
    "To do this in one line, we reference the DataFrame we are selecting from, and then place our filter condition within the indexing or selection brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_over_4 = cat_dog[(cat_dog[\"animal\"] == \"Cat\") & (cat_dog[\"age\"] > 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c8073",
   "metadata": {},
   "source": [
    "If we can use the AND condition (&) we can also use the OR condition where only one of the conditions must be met to evaluate to `True`.\n",
    "\n",
    "The OR condition is represented by a vertical bar symbol ( `|` ) – press shift and `\\`.\n",
    "\n",
    "Lets add a condition where the animal is a cat **OR** the age is greater than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create my mask\n",
    "mask = (cat_dog[\"animal\"] == \"Cat\") | (cat_dog[\"age\"] > 4)\n",
    "\n",
    "# View mask\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4b1a7",
   "metadata": {},
   "source": [
    "Let's look at the `mask` values alongside the DataFrame:\n",
    "\n",
    "|   | animal  |       name      | age | included |\n",
    "|:-:|:-------:|:---------------:|-----|----------|\n",
    "| 0 |   Cat   | Catalie Portman | 3   | True     |\n",
    "| 1 |   Cat   |   Pico de Gato  | 5   | True     |\n",
    "| 2 |   Dog   |    Chewbarka    | 1   | False    |\n",
    "| 3 |   Cat   |   Sir Isaac Mewton   | 7   | True     |\n",
    "| 4 | Dog     | K9              | 11  | True     |\n",
    "\n",
    "Catalie Portman now evaluates to True. While she is younger than 3 she is a Cat, and by meeting one of the conditions, she is included.\n",
    "\n",
    "K9 also evaluates to `True`. He is not a cat; but meets the age condition by being older than 4 and so is included.\n",
    "\n",
    "We can of course apply this mask to filter the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75571968",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_or_over4 = cat_dog[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b9d3d",
   "metadata": {},
   "source": [
    "Or do the whole action in one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dcb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_or_over4 = cat_dog[(cat_dog[\"animal\"] == \"Cat\") | (cat_dog[\"age\"] > 4)]\n",
    "\n",
    "cats_or_over4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31dbbc",
   "metadata": {},
   "source": [
    "Here are some more examples using the `titanic` DataFrame.\n",
    "\n",
    "Here we are filtering for survivors (value 1), who were female. Using an AND (&) condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_survivors = titanic[(titanic[\"survived\"] == 1) & (titanic[\"sex\"] == \"female\")]\n",
    "female_survivors.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2e4c9",
   "metadata": {},
   "source": [
    "And here we are filtering for those with more than 3 sibling/spouses (`sibsp`) on board or who paid more than £400 for their fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings_or_expensive = titanic[(titanic['sibsp'] > 3) | (titanic['fare'] > 400)]\n",
    "siblings_or_expensive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4aceb",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) Filter the animals DataFrame where the IncidentNominalCost(£) Column was less than £400 **and** where the Borough column value is Croydon. \n",
    "\n",
    "(b) Filter the animals DataFrame where the 'PropertyType' was \"River/canal\" **or** the `\"PumpHoursTotal\"` was at most 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030698f6",
   "metadata": {},
   "source": [
    "## Some Filter short cuts.\n",
    "\n",
    "We can also use some other filters to make life easier.\n",
    "\n",
    "### Example 1\n",
    "\n",
    "With the method `.isin()` we can provide a list of things to filter, here the boat identities `[“2”, “C”, “15”]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic[\"boat\"].isin([\"2\", \"C\", \"15\"])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be55a18",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "If dealing with numeric values we can use `.between()` and specify an upper and lower bound. Here we’re looking where the `age` column was between 0 and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic[\"age\"].between(0, 12)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839742e3",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "We also have the `~` tilde symbol to invert an expression, this works similarly to the `!=` for does not equal. For example, I can invert the filter for female passengers to return just male passengers.\n",
    "\n",
    "Note that I have to wrap my conditional statement in round brackets to ensure this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[~(titanic[\"sex\"] == \"female\")].head()  # Inverts the results of == Female; effectively giving == Male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175690b",
   "metadata": {},
   "source": [
    "The tilde `~` can be useful for other scenarios, there’s a variety of `.is` methods for example that do not have an is not equivalent; but we can invert the `.is` method instead. We’ll see a useful example of that in chapter 5. \n",
    "\n",
    "### Filtering Text\n",
    "\n",
    "So far when we've talked about filtering text we do so on exact matches. However, as Python is case sensitive, filtering for `“cat”` will not show the values `“CAT”` or `“Cat”` in our `cat_dog` DataFrame, should they exist (which they often will in real world data). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6167d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create our cat_dog DataFrame again with some variation in the capitalisation of \"cat\"\n",
    "\n",
    "cat_dog_wrong_spelling = pd.DataFrame({\"animal\": [\"cat\", \"Cat\", \"Dog\", \"cat\", \"Dog\", \"Rat\", \"Bat\"] , \n",
    "                                       \"name\": [\"Catalie Portman\",\"Pico de Gato\", \"Chewbarka\", \"Sir Isaac Mewton\", \"K9\", \"Roland\", \"Vlad\"],\n",
    "                                       \"age\": [3, 5, 1, 7, 11, 1, 3]} , \n",
    "                                      columns = [\"name\", \"animal\", \"age\"])\n",
    "\n",
    "cat_dog_wrong_spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36523d4",
   "metadata": {},
   "source": [
    "Here the filter condition we previously used (`== Cat`) will only now only return us `Pico De Gato`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e14b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_only_spelling = cat_dog_wrong_spelling[cat_dog_wrong_spelling[\"animal\"] == \"Cat\"]\n",
    "cat_only_spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf91e7",
   "metadata": {},
   "source": [
    "Which is not the result we wanted.\n",
    "\n",
    "### Example\n",
    "\n",
    "For simple instances we can use the string method `str.contains()` like in the example below. Here, in our DataFrame, some entries in the `\"Animal\"` column have \"Cat\" and others have \"cat\". By using `.str.contains(“at”)`, we can bring in both values because both contain the partial string \"at\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b20486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to find instances where the string in \"animal\" contains \"at\"\n",
    "cat_only_spelling = cat_dog_wrong_spelling[cat_dog_wrong_spelling[\"animal\"].str.contains(\"at\")]\n",
    "cat_only_spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61664d",
   "metadata": {},
   "source": [
    "This is clearly not foolproof however, as both `Rat` and `Bat` also have `at` in them, and as such are displayed in the output. \n",
    "\n",
    "In chapter 5 we'll look at changing the column values and column names to lowercase letters, which would allow a straight forward filter to work in this case.\n",
    "\n",
    "## Aside - Regular Expressions\n",
    "\n",
    "For more complex cases we can use what is known as Regular Expressions or RegEx in Python to search for partial strings with specified conditions (such as placing where the letters are located, starting with, ending with etc).\n",
    "\n",
    "We do not cover these in this introduction course; but here are some more resources you may wish to explore. If you have used Regular Expressions in other languages you will find this very familiar.\n",
    "\n",
    "[RegEx How to]( https://docs.python.org/3/howto/regex.html)\n",
    "\n",
    "[Python Regular Expressions]( https://developers.google.com/edu/python/regular-expressions)\n",
    "\n",
    "[Datacamp RegEx tutorial]( https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial)\n",
    "\n",
    "## More Filtering Methods\n",
    "\n",
    "We’ve looked here at the base Python way of filtering, but as with many things in Python there are other alternatives. \n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb028834",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.query('fare > 50 & sex == \"male\"').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc4bb9",
   "metadata": {},
   "source": [
    "Here we use `.query()` which allows us to type a more SQL style query in words and symbols without utilising our filtering brackets.\n",
    "\n",
    "### Example 2\n",
    "\n",
    "We also have `.filter()`, which works on the *index*, rather then the contents! Here I’m looking for `like = “1”` which will give me index `1` , `11` , `12` as they contain the number 1. Note that `axis = 0` means apply to the **rows**, whereas `axis = 1` applies to the columns. \n",
    "\n",
    "So far we’ve worked with indexes that are numerical, from 0 to n; but they can also be text based; and using the pandas `.filter()` would be useful here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.filter(like = \"1\", axis = 0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b3d83",
   "metadata": {},
   "source": [
    "You may find even more ways of filtering your data when researching, there’s lots out there!\n",
    "\n",
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab536f",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92be81",
   "metadata": {},
   "source": [
    "# Deriving New Columns\n",
    "\n",
    "We create new columns in very similar to filtering them:\n",
    "\n",
    "<center> `titanic[\"new_column\"] = 1` </center>\n",
    "\n",
    "In the example above we are creating a new column in the `titanic` DataFrame called `\"new_column\"`, which will have the constant value of 1 in each row.\n",
    "\n",
    "* To create a new column we first give the DataFrame name and use square brackets to specify, as a string our column name, here this is `\"new_column\"`.\n",
    "    * If the column name does not exist in our Dataframe (like in the example) the contents will be placed in a new column, at the end of the DataFrame.\n",
    "    * If the column already exists in our DataFrame the contents of that column will be **overwritten**.\n",
    "    \n",
    "We then use the assignment operator ` = ` and after this is what we fill our column with, in this example it was a constant value of the integer 1. \n",
    "\n",
    "We’ll now look at various different ways we can fill these new columns.\n",
    "\n",
    "## Other Constant Values\n",
    "\n",
    "Some more examples are in the cell below, filling with both floats as well as objects/strings. The syntax remains the same, subsetting the column and assigning it to the value.\n",
    "\n",
    "### Example\n",
    "\n",
    "As a reminder, our cat_dog dataframe looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d4aed",
   "metadata": {},
   "source": [
    "Now let's add some more constant columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog[\"constant_string\"] = \"mammal\"   # adds a string/object constant\n",
    "cat_dog[\"constant_float\"] = 3.2 # adds a floating point constant\n",
    "cat_dog[\"constant_int\"] = 2   # adds an interger constant\n",
    "\n",
    "cat_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b8a9e",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Add a new constant column to the `animals` DataFrame called `attended` and set the value to be `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2ed89",
   "metadata": {},
   "source": [
    "## Numeric Values\n",
    "\n",
    "We can create numeric columns as well, which are often referred to as 'calculated columns' as they can be calculated referencing many other numeric columns. \n",
    "\n",
    "### Example\n",
    "\n",
    "We can do any form of operations we like here, for example creating the family size of the person. This is the number of siblings or spouses on board (`sibsp`), the number of parents or children on board (`parch`), plus 1 (the person themselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f114c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"family_size\"] = titanic[\"sibsp\"] + titanic[\"parch\"] + 1\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160de0b",
   "metadata": {},
   "source": [
    "## Boolean and Binary Values\n",
    "\n",
    "Using the same conditions as we do when filtering we can also create Boolean (True/False) columns. This is very common practice when we want to create binary columns (which can be very useful for visualisation and analysis purposes).\n",
    "\n",
    "### Example\n",
    "\n",
    "In the example below I am assigning `True` to all values in the `age` column that are under 18. My new column is called `\"under_18\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"under_18_bool\"] = titanic[\"age\"] < 18\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf2216",
   "metadata": {},
   "source": [
    "We can also change these values from the Boolean `True` and `False` to the binary values `1` and `0`, which is the key change we make when it comes to building models (it is often required that all values are numeric for example). \n",
    "\n",
    "We can convert columns by using the code `.astype(“int64”)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91193a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"under_18_binary\"] = titanic[\"under_18_bool\"].astype(\"int64\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa1a85",
   "metadata": {},
   "source": [
    "We can also do this in one step when we create the column. We can wrap the first part of the code in brackets; like our order of operations in mathematics (BIDMAS, BODMAS whatever you referred to it as) this tells Python which bit to do first.\n",
    "\n",
    "In the cell below we add the new column in one line, and then sort out the missing values in the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new column and change the type in one line\n",
    "\n",
    "titanic[\"under_18_binary\"] = (titanic[\"age\"] < 18).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378adbe",
   "metadata": {},
   "source": [
    "It’s important to note that where we have missing values, it will mark those as `False` (or 0). We’ll look at one way of fixing this after the exercises, but for a full look into missing values, stay tuned for Chapter 5!\n",
    "\n",
    "### Example\n",
    "\n",
    "The following code uses the `.isnull()` method to single out where there are missing values. This is wrapped up in the indexing brackets [], so we end up with all rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec18e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['age'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392543e1",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "(a) Create a new boolean column in the `animals` DataFrame called `fish_bool`. Use the `AnimalClass` column to find the values that are eqivalant to `Fish`.\n",
    "\n",
    "(b) Convert `fish_bool` to a numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cddb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise \n",
    "\n",
    "# (a) \n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc1503",
   "metadata": {},
   "source": [
    "### More on the issue of Booleans and Missing Values\n",
    "\n",
    "Earlier we declared a boolean column that has `True` for under 18, and `False` for over 18. One issue with this method is that if an entry in the `age` column is a missing value (`NaN`) then it is classified as `False` here.\n",
    "\n",
    "While Pandas has done exactly as we asked (it does not meet the criteria so is `False`) we’re artificially inflating the number of adults in our two end columns. \n",
    "\n",
    "Statistically this isn’t right. There's 263 missing values in the `age` column, as we don’t know the passengers age; so we should preserve the missing data types rather than assume they're over 18 (as it currently does!)\n",
    "\n",
    "### Example\n",
    "\n",
    "To illustrate, the cell below is filtering the `titanic` dataframe, showing the values that are null (using `.isnull()`) in the `age` column.\n",
    "\n",
    "You can see that they show `False` in the `under_18` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913db1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"under_18\" column again - in case it's not been run yet!\n",
    "titanic[\"under_18_bool\"] = titanic[\"age\"] < 18\n",
    "\n",
    "# Look at missing values in the age column\n",
    "# Note that in the \"under_18\" column - they are True!\n",
    "\n",
    "titanic[titanic['age'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77811e1a",
   "metadata": {},
   "source": [
    "## Example - Filling in missing values with a constant\n",
    "\n",
    "We’ll look at more ways to action missing values in chapter 6; but for now we can use `.loc[]` to fill in these values. \n",
    "\n",
    "We’ll also talk about `.loc[]` in chapter 5 and in the extension chapter 7. Basically, `.loc[]` can look up rows or columns based on either their index; or as we’re doing here, a logical statement like a filter statement.\n",
    "\n",
    "Here we’re using `.loc[]` to find rows where the `age` column has a null value; and updating our new column `under_18` to show null (`NaN`) too using the keyword `None`. See that `loc[]` takes two inputs, the condition (here that is whether it is null), then the column to apply that too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed601bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic['age'].isnull(), 'under_18_bool'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac192a2f",
   "metadata": {},
   "source": [
    "Now our `NaN` in `age` are also `NaN` values in `under_18`, as we can see if we run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999989d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['age'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169815cc",
   "metadata": {},
   "source": [
    "While we still have missing data in this column that we may want to deal with later (see chapter 6); at least our “under_18” column is now more accurate. It's really important we think about missing values whenever we perform operations using our data.\n",
    "\n",
    "Even just recoding values not considered missing is a very important step when analysing and cleaning our data, as this informs us on how to treat the column.\n",
    "\n",
    "## Mapping New Values\n",
    "\n",
    "We can also use `.map()` to map a dictionary to a column.\n",
    "\n",
    "This can be useful when we want to explain coded variables for other users; e.g. the column `embarked` has the values `S`, `C` and `Q`.  We can use `.map()` to give the full names of these ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"port\"] = titanic[\"embarked\"].map({\"S\":\"Southampton\",\n",
    "                                           \"C\":\"Cherbourg\", \n",
    "                                           \"Q\": \"Queenstown (Cobh)\"})\n",
    "\n",
    "titanic.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09879c",
   "metadata": {},
   "source": [
    "The usefulness of this process cannot be overstated, many times we will be handed data in the real world that has many of these very confusing acronyms, initials etc. Recoding them to be more descriptive and easier to work with can be a lifesaver in certain situations!\n",
    "\n",
    "## Deleting columns\n",
    "\n",
    "There are a few ways to remove or drop columns.\n",
    "\n",
    "Let's look at cat_dog again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1286fa",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "We have the inbuilt python statement del, which we can follow with a selected column to permanently delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16412c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cat_dog[\"constant_float\"]\n",
    "cat_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26414206",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "We can also use the `.drop()` method.\n",
    "\n",
    "For Pandas version 0.21.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog.drop(columns = [\"constant_string\", \"constant_int\"], inplace = True)\n",
    "\n",
    "# If this cell doesn't work check your version using pd.__version__\n",
    "# If lower than 0.21.0 use the code in the text below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec51cfc",
   "metadata": {},
   "source": [
    "Here note:\n",
    "\n",
    "* I’m passing my column names as a list, as there’s more than one\n",
    "* `inplace=True`  updates the original Dataframe\n",
    "\n",
    "This is a very good example of how packages can evolve over time. For versions lower than 0.21.0 of Pandas we have to provide `axis = 1`, as it can't detect if you’re dealing with columns or rows. The code for this will be as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog.drop(labels=[\"constant_string\", \"constant_int\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f8985",
   "metadata": {},
   "source": [
    "In ONS some people still use version 0.20.0 so the “old” syntax is included here for completeness. An additional option is to use square brackets to just return the columns we want to, which we covered that earlier in this section.\n",
    "\n",
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863952da",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97462976",
   "metadata": {},
   "source": [
    "<a id='merge'></a>\n",
    "\n",
    "# Merging Data\n",
    "\n",
    "Let’s have a look at the two `joining_data` DataFrames we loaded in at the start of the chapter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cbf6d5",
   "metadata": {},
   "source": [
    "* In `joining_data1` we have the columns `name`, `animal` and `age`.\n",
    "* In `joining_data2` we have the columns `name` and `vaccinated`.\n",
    "\n",
    "We see that `Arf Vader` only appears in `joining_data1` and `Spiderpig` only appears in `joining_data2`. The remainder of the animals appear in both DataFrames.\n",
    "\n",
    "## Types of Join \n",
    "\n",
    "These two DataFrames have a column in common that we could use to join them on, which is `name`. Without this we could not join the datasets together as this is the stipulation to perform a merge/join. \n",
    "\n",
    "We can create a variety of joins. These are often best demonstrated with a Venn diagram. From here, I’m going to say that `joining_data1` is my “left” DataFrame, and that `joining_data2` is my “right” DataFrame.\n",
    "\n",
    "For this I’m going to highlight the position of 3 animal names. As we mentioned earlier:\n",
    "\n",
    "* `Arf Vader` is only in `joining_data1`, our “left” DataFrame.\n",
    "* `Spiderpig` is only in `joining_data2`, our “right” DataFrame \n",
    "* `Catalie Portman` is in both `joining_data1` and `joining_data2` and will represent values in BOTH DataFrames. \n",
    "\n",
    "![\"examples of merge\"](../images/pdmerge.png)\n",
    "\n",
    "As you can see `left` and `right` merges take the data from that DataFrame and any matches from the opposite one. \n",
    "\n",
    "This means that in our `left`:\n",
    "\n",
    "* `Arf Vader` is included because he has data in the left DataFrame. \n",
    "* `Arf Vader` has missing values for `vaccinated`, as he isn’t in that DataFame\n",
    "* `Catalie Portman` has data in all columns, as she appears in both the left and right\n",
    "* `Spiderpig` doesn’t have any data. We’re only taking data from the left, and he’s only in the right.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let’s look at how we do this left merge in code. We’re going to use `pd.merge()` and do a left join.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merge = pd.merge(left = joining_data1,\n",
    "                      right=joining_data2, \n",
    "                                 how=\"left\",\n",
    "                                 on=\"name\",\n",
    "                                 indicator=True)\n",
    "\n",
    "left_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b58f8b",
   "metadata": {},
   "source": [
    "This is the most layered method we have seen so far, with numerous arguments we must utilise to perform the joins we want. \n",
    "\n",
    "* `left = ` is our left hand DataFrame\n",
    "* `right = ` is our right hand DataFrame\n",
    "* `how = ` is how we want to perform the join, other options are\n",
    "  - `right`\n",
    "  - `outer`\n",
    "  - `inner`  (default behaviour)\n",
    "* ` on = ` is the name of the column both DataFrames have in common. If we're joining on more than one column we can specify a list here.\n",
    "* ` indicator` set to `True` adds an additional column showing if the data was in the left_only, both or right_only as applicable, which is excellent for checking.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "(a) Using `marvel_left` and `marvel_right` that we loaded in earlier, perform an outer join using the column `name`. Include the column that specifies whether they came from the left or right DataFrame.\n",
    "\n",
    "(b) Using `marvel_left` and `marvel_right` perform a left join on the column containing the years. Note that the names of these columns may not be the same in both DataFrames! (Hint: Use the help function to observe optional arguments to help with this).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise\n",
    "\n",
    "# (a)\n",
    "\n",
    "# (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e220fe",
   "metadata": {},
   "source": [
    "Notice here we use the parameter `left_on` to list the names of the columns in our left dataframe and `right_on` for the names of the columns in our right.\n",
    "\n",
    "We see here that maybe the year is not the best joining column! We’re getting multiple joins for movies that have different names because we only need that “year” data to match. \n",
    "\n",
    "The solution to this is to join on more than one column, which you will do next!\n",
    "\n",
    "### Extension Exercise\n",
    "\n",
    "Modify the join from (b) in the previous Exercise to:\n",
    "\n",
    "* Join on **BOTH** the column containing names and the column containing years. Remember that the names may differ across the dataframes! \n",
    "\n",
    "Hint: How did we specify multiple columns in previous chapters? Remember order is important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Extension Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483ae7e",
   "metadata": {},
   "source": [
    "Notice here we use the parameter left_on to list the names of the columns in our left dataframe and right_on for the names of the columns in our right and as we're using multiple columns these are in lists. This would be a great solution if we had a larger dataset to work with.\n",
    "\n",
    "For example in 1998 there was a movie called “The Avengers”. It's not a marvel movie, and does not star Iron Man, but instead Uma Thurman and Ralph Fiennes as spys! By using the name and year we'd ensure a higher level of accuracy, being as specific as you can is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f5c29",
   "metadata": {},
   "source": [
    "## Union Merge\n",
    "\n",
    "We can also do what's known as `union` merges, which is implemented using `pd.concat()`.This is where we can add data on to the bottom of an existing dataFrame (like an appending motion).\n",
    "\n",
    "It is so important that the columns of each DataFrame are in the same order, otherwise the union operation will fail (remember, columns can only have one datatype!).\n",
    "\n",
    "### Example\n",
    "\n",
    "For example we have some new animals to add on to `joining_data1`, these are contained in the `union_joined` DataFrame we loaded in earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af08064",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_joined = pd.concat(objs=[joining_data1, union_join_data], ignore_index=True)\n",
    "union_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620b6eb",
   "metadata": {},
   "source": [
    "We can see our new additions, namely `Andy Warhowl`, `Voldetort` and `Repecka` here now.\n",
    "\n",
    "Our parameters and arguments in `pd.conact()` are:\n",
    "* `objs= ` Our objects that we wish to concatenate, here as a list\n",
    "* `ignore_index= ` My new DataFrame will have it’s “own” index starting from 0. If I set this to `False` then I will have two things with an index of 0 and I don’t want that as this will cause frustration later!\n",
    "\n",
    "This is a very rich topic (as are most processes in Pandas!) and other interesting methods exist that allow us to combine in different ways. For example, `.append()` and `.join()` also exist, here’s a link with a lot more detail about joining together data. [Merge, Join, Concatenate and Compare]( https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1c074",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9b760",
   "metadata": {},
   "source": [
    "# Chapter Summary \n",
    "\n",
    "Amazing work! Congratulations on completing Chapter 4 of the Introduction to Python Course, you are now a DataFrame Wizard! \n",
    "\n",
    "In Chapter 5 we will focus on applying the various methods we covered here to clean our data, preparing it ready for the tasks that follow such as Aggregation and Summary (Chapter 6) and Visualisation (Future courses on the Learning Hub). We will cover:\n",
    "\n",
    "* Copies and Views\n",
    "* Updating Values\n",
    "* Changing Column Names\n",
    "* Missing Values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
